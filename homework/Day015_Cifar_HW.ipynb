{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用這幾天所學觀念搭建一個CNN分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉CNN分類器搭建步驟與原理\n",
    "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 2021057574825988941\n, name: \"/device:GPU:0\"\ndevice_type: \"GPU\"\nmemory_limit: 4963368960\nlocality {\n  bus_id: 1\n  links {\n  }\n}\nincarnation: 3161382640087171797\nphysical_device_desc: \"device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7) \n",
    "        return X_train, X_test,mean,std\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test,mean_train,std_train = normalize(x_train, x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.fit_transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=Sequential()\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(filters = 32 ,kernel_size=(3,3) ,strides = 1 ,padding = 'same',input_shape=(32,32,3),activation='relu'))\n",
    "classifier.add(MaxPooling2D(2,2))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Convolution2D(filters = 64 ,kernel_size=(3,3) ,strides = 1 ,padding = 'same',activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(2,2))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Convolution2D(filters = 32 ,kernel_size=(3,3) ,strides = 1 ,padding = 'same',activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(2,2))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "#FC\n",
    "classifier.add(Dense(100,activation = \"relu\",kernel_regularizer=regularizers.l2(l=0.001))) \n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dense(100,activation = \"relu\",kernel_regularizer=regularizers.l2(l=0.001)))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dense(100,activation = \"relu\",kernel_regularizer=regularizers.l2(l=0.001)))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "\n",
    "\n",
    "#輸出\n",
    "classifier.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ge = ImageDataGenerator(\n",
    " featurewise_center=True,\n",
    " featurewise_std_normalization=True,\n",
    " rotation_range=10,\n",
    " width_shift_range=0.1,\n",
    " height_shift_range=0.1,\n",
    " shear_range=0.1,\n",
    " zoom_range=0.1,\n",
    " horizontal_flip=True,\n",
    " vertical_flip=False,\n",
    " dtype=np.float32\n",
    ")\n",
    "\n",
    "image_ge.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = load_model('./test0425.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 1.0166 - accuracy: 0.7443 - val_loss: 0.8501 - val_accuracy: 0.7824\n",
      "Epoch 2/100\n",
      "2000/2000 [==============================] - 23s 12ms/step - loss: 1.0134 - accuracy: 0.7466 - val_loss: 0.7773 - val_accuracy: 0.8023\n",
      "Epoch 3/100\n",
      "2000/2000 [==============================] - 23s 12ms/step - loss: 1.0208 - accuracy: 0.7441 - val_loss: 0.8436 - val_accuracy: 0.7792\n",
      "Epoch 4/100\n",
      "2000/2000 [==============================] - 23s 12ms/step - loss: 1.0244 - accuracy: 0.7441 - val_loss: 0.8857 - val_accuracy: 0.7671\n",
      "Epoch 5/100\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 1.0198 - accuracy: 0.7455 - val_loss: 0.8198 - val_accuracy: 0.7906\n",
      "Epoch 6/100\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 1.0185 - accuracy: 0.7463 - val_loss: 0.8131 - val_accuracy: 0.7886\n",
      "Epoch 7/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 1.0216 - accuracy: 0.7434 - val_loss: 0.8421 - val_accuracy: 0.7810\n",
      "Epoch 8/100\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 1.0218 - accuracy: 0.7452 - val_loss: 0.8430 - val_accuracy: 0.7810\n",
      "Epoch 9/100\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 1.0089 - accuracy: 0.7490 - val_loss: 0.8005 - val_accuracy: 0.7920\n",
      "Epoch 10/100\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 1.0244 - accuracy: 0.7452 - val_loss: 0.8322 - val_accuracy: 0.7887\n",
      "Epoch 11/100\n",
      "2000/2000 [==============================] - 23s 12ms/step - loss: 1.0134 - accuracy: 0.7499 - val_loss: 0.8572 - val_accuracy: 0.7821\n",
      "Epoch 12/100\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 1.0120 - accuracy: 0.7477 - val_loss: 0.7784 - val_accuracy: 0.8048\n",
      "Epoch 13/100\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 1.0182 - accuracy: 0.7476 - val_loss: 0.8197 - val_accuracy: 0.7924\n",
      "Epoch 14/100\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 1.0132 - accuracy: 0.7488 - val_loss: 0.9034 - val_accuracy: 0.7641\n",
      "Epoch 15/100\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 1.0042 - accuracy: 0.7485 - val_loss: 0.8348 - val_accuracy: 0.7844\n",
      "Epoch 16/100\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 1.0157 - accuracy: 0.7470 - val_loss: 0.8287 - val_accuracy: 0.7900\n",
      "Epoch 17/100\n",
      "2000/2000 [==============================] - 23s 12ms/step - loss: 1.0076 - accuracy: 0.7498 - val_loss: 0.8554 - val_accuracy: 0.7793\n",
      "Epoch 18/100\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 1.0150 - accuracy: 0.7477 - val_loss: 0.8212 - val_accuracy: 0.7876\n",
      "Epoch 19/100\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 1.0200 - accuracy: 0.7441 - val_loss: 0.8964 - val_accuracy: 0.7674\n",
      "Epoch 20/100\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 1.0104 - accuracy: 0.7492 - val_loss: 0.8033 - val_accuracy: 0.7978\n",
      "Epoch 21/100\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 1.0043 - accuracy: 0.7486 - val_loss: 0.8409 - val_accuracy: 0.7819\n",
      "Epoch 22/100\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 1.0174 - accuracy: 0.7449 - val_loss: 0.8376 - val_accuracy: 0.7835\n",
      "Epoch 23/100\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 1.0160 - accuracy: 0.7475 - val_loss: 0.8366 - val_accuracy: 0.7860\n",
      "Epoch 24/100\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 1.0133 - accuracy: 0.7494 - val_loss: 0.8118 - val_accuracy: 0.7966\n",
      "Epoch 25/100\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 1.0099 - accuracy: 0.7487 - val_loss: 0.7887 - val_accuracy: 0.8032\n",
      "Epoch 26/100\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 1.0096 - accuracy: 0.7478 - val_loss: 0.8207 - val_accuracy: 0.7907\n",
      "Epoch 27/100\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 1.0092 - accuracy: 0.7501 - val_loss: 0.8047 - val_accuracy: 0.7977\n",
      "Epoch 28/100\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 1.0088 - accuracy: 0.7492 - val_loss: 0.8511 - val_accuracy: 0.7815\n",
      "Epoch 29/100\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 1.0106 - accuracy: 0.7483 - val_loss: 0.7831 - val_accuracy: 0.8025\n",
      "Epoch 30/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 1.0166 - accuracy: 0.7474 - val_loss: 0.8505 - val_accuracy: 0.7856\n",
      "Epoch 31/100\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 1.0104 - accuracy: 0.7491 - val_loss: 0.8363 - val_accuracy: 0.7837\n",
      "Epoch 32/100\n",
      "2000/2000 [==============================] - 23s 12ms/step - loss: 1.0113 - accuracy: 0.7507 - val_loss: 0.8369 - val_accuracy: 0.7852\n",
      "Epoch 33/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 1.0131 - accuracy: 0.7482 - val_loss: 0.8206 - val_accuracy: 0.7904\n",
      "Epoch 34/100\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 1.0128 - accuracy: 0.7487 - val_loss: 0.9228 - val_accuracy: 0.7538\n",
      "Epoch 35/100\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 1.0118 - accuracy: 0.7504 - val_loss: 0.8573 - val_accuracy: 0.7783\n",
      "Epoch 36/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 1.0069 - accuracy: 0.7519 - val_loss: 0.7896 - val_accuracy: 0.8011\n",
      "Epoch 37/100\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 1.0122 - accuracy: 0.7495 - val_loss: 0.8463 - val_accuracy: 0.7832\n",
      "Epoch 38/100\n",
      "2000/2000 [==============================] - 23s 12ms/step - loss: 1.0085 - accuracy: 0.7513 - val_loss: 0.8522 - val_accuracy: 0.7787\n",
      "Epoch 39/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 1.0058 - accuracy: 0.7487 - val_loss: 0.8168 - val_accuracy: 0.7889\n",
      "Epoch 40/100\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 1.0092 - accuracy: 0.7478 - val_loss: 0.8312 - val_accuracy: 0.7898\n",
      "Epoch 41/100\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 1.0020 - accuracy: 0.7522 - val_loss: 0.8146 - val_accuracy: 0.7906\n",
      "Epoch 42/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 1.0020 - accuracy: 0.7522 - val_loss: 0.8477 - val_accuracy: 0.7763\n",
      "Epoch 43/100\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 1.0120 - accuracy: 0.7477 - val_loss: 0.9367 - val_accuracy: 0.7522\n",
      "Epoch 44/100\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 1.0111 - accuracy: 0.7485 - val_loss: 0.8606 - val_accuracy: 0.7780\n",
      "Epoch 45/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 1.0082 - accuracy: 0.7509 - val_loss: 0.7733 - val_accuracy: 0.8043\n",
      "Epoch 46/100\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.9973 - accuracy: 0.7524 - val_loss: 0.8355 - val_accuracy: 0.7889\n",
      "Epoch 47/100\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 1.0071 - accuracy: 0.7505 - val_loss: 0.8464 - val_accuracy: 0.7865\n",
      "Epoch 48/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 1.0047 - accuracy: 0.7506 - val_loss: 0.7966 - val_accuracy: 0.7957\n",
      "Epoch 49/100\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 1.0034 - accuracy: 0.7511 - val_loss: 0.8516 - val_accuracy: 0.7779\n",
      "Epoch 50/100\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 1.0030 - accuracy: 0.7516 - val_loss: 0.8495 - val_accuracy: 0.7783\n",
      "Epoch 51/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 1.0064 - accuracy: 0.7501 - val_loss: 0.8110 - val_accuracy: 0.7965\n",
      "Epoch 52/100\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 1.0113 - accuracy: 0.7484 - val_loss: 0.7817 - val_accuracy: 0.8041\n",
      "Epoch 53/100\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 1.0004 - accuracy: 0.7541 - val_loss: 0.8839 - val_accuracy: 0.7783\n",
      "Epoch 54/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 0.9945 - accuracy: 0.7555 - val_loss: 0.9040 - val_accuracy: 0.7671\n",
      "Epoch 55/100\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 1.0053 - accuracy: 0.7512 - val_loss: 0.8565 - val_accuracy: 0.7788\n",
      "Epoch 56/100\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 1.0067 - accuracy: 0.7510 - val_loss: 0.7826 - val_accuracy: 0.8083\n",
      "Epoch 57/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 1.0090 - accuracy: 0.7524 - val_loss: 0.8368 - val_accuracy: 0.7883\n",
      "Epoch 58/100\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 1.0056 - accuracy: 0.7522 - val_loss: 0.8027 - val_accuracy: 0.7973\n",
      "Epoch 59/100\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 1.0055 - accuracy: 0.7503 - val_loss: 0.9079 - val_accuracy: 0.7675\n",
      "Epoch 60/100\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 0.9940 - accuracy: 0.7548 - val_loss: 0.8217 - val_accuracy: 0.7931\n",
      "Epoch 61/100\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 1.0033 - accuracy: 0.7516 - val_loss: 0.8332 - val_accuracy: 0.7861\n",
      "Epoch 62/100\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 0.9941 - accuracy: 0.7544 - val_loss: 0.8268 - val_accuracy: 0.7920\n",
      "Epoch 63/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 1.0153 - accuracy: 0.7496 - val_loss: 0.8437 - val_accuracy: 0.7827\n",
      "Epoch 64/100\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 1.0068 - accuracy: 0.7500 - val_loss: 0.8157 - val_accuracy: 0.7914\n",
      "Epoch 65/100\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 0.9956 - accuracy: 0.7521 - val_loss: 0.7662 - val_accuracy: 0.8086\n",
      "Epoch 66/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 1.0085 - accuracy: 0.7491 - val_loss: 0.8249 - val_accuracy: 0.7936\n",
      "Epoch 67/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 1.0120 - accuracy: 0.7488 - val_loss: 0.8272 - val_accuracy: 0.7896\n",
      "Epoch 68/100\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 1.0040 - accuracy: 0.7495 - val_loss: 0.7956 - val_accuracy: 0.8009\n",
      "Epoch 69/100\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 0.9979 - accuracy: 0.7529 - val_loss: 0.8360 - val_accuracy: 0.7858\n",
      "Epoch 70/100\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 1.0011 - accuracy: 0.7541 - val_loss: 0.8598 - val_accuracy: 0.7826\n",
      "Epoch 71/100\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 1.0017 - accuracy: 0.7546 - val_loss: 0.8199 - val_accuracy: 0.7903\n",
      "Epoch 72/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 1.0005 - accuracy: 0.7549 - val_loss: 0.8208 - val_accuracy: 0.7923\n",
      "Epoch 73/100\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 1.0050 - accuracy: 0.7520 - val_loss: 0.8242 - val_accuracy: 0.7879\n",
      "Epoch 74/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 1.0008 - accuracy: 0.7532 - val_loss: 0.8958 - val_accuracy: 0.7669\n",
      "Epoch 75/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 0.9996 - accuracy: 0.7534 - val_loss: 0.8282 - val_accuracy: 0.7884\n",
      "Epoch 76/100\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.9908 - accuracy: 0.7553 - val_loss: 0.8166 - val_accuracy: 0.7933\n",
      "Epoch 77/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 1.0029 - accuracy: 0.7518 - val_loss: 0.9055 - val_accuracy: 0.7662\n",
      "Epoch 78/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 0.9964 - accuracy: 0.7536 - val_loss: 0.8601 - val_accuracy: 0.7832\n",
      "Epoch 79/100\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.9879 - accuracy: 0.7582 - val_loss: 0.8157 - val_accuracy: 0.7916\n",
      "Epoch 80/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 1.0012 - accuracy: 0.7511 - val_loss: 0.8057 - val_accuracy: 0.7966\n",
      "Epoch 81/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 0.9957 - accuracy: 0.7547 - val_loss: 0.8532 - val_accuracy: 0.7776\n",
      "Epoch 82/100\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 1.0050 - accuracy: 0.7505 - val_loss: 0.8150 - val_accuracy: 0.7938\n",
      "Epoch 83/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 0.9950 - accuracy: 0.7542 - val_loss: 0.8483 - val_accuracy: 0.7934\n",
      "Epoch 84/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 0.9959 - accuracy: 0.7530 - val_loss: 0.7788 - val_accuracy: 0.8005\n",
      "Epoch 85/100\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.9928 - accuracy: 0.7557 - val_loss: 0.8233 - val_accuracy: 0.7928\n",
      "Epoch 86/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 0.9958 - accuracy: 0.7530 - val_loss: 0.8709 - val_accuracy: 0.7772\n",
      "Epoch 87/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 1.0013 - accuracy: 0.7528 - val_loss: 0.8219 - val_accuracy: 0.7937\n",
      "Epoch 88/100\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 0.9877 - accuracy: 0.7562 - val_loss: 0.8149 - val_accuracy: 0.7916\n",
      "Epoch 89/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 0.9968 - accuracy: 0.7538 - val_loss: 0.8470 - val_accuracy: 0.7808\n",
      "Epoch 90/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 0.9995 - accuracy: 0.7531 - val_loss: 0.7882 - val_accuracy: 0.8011\n",
      "Epoch 91/100\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.9993 - accuracy: 0.7539 - val_loss: 0.8192 - val_accuracy: 0.7905\n",
      "Epoch 92/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 0.9918 - accuracy: 0.7546 - val_loss: 0.7991 - val_accuracy: 0.7967\n",
      "Epoch 93/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 0.9964 - accuracy: 0.7536 - val_loss: 0.7955 - val_accuracy: 0.7979\n",
      "Epoch 94/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 1.0001 - accuracy: 0.7521 - val_loss: 0.7831 - val_accuracy: 0.7989\n",
      "Epoch 95/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 1.0034 - accuracy: 0.7512 - val_loss: 0.8122 - val_accuracy: 0.7903\n",
      "Epoch 96/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 1.0006 - accuracy: 0.7551 - val_loss: 0.8260 - val_accuracy: 0.7920\n",
      "Epoch 97/100\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.9877 - accuracy: 0.7564 - val_loss: 0.8530 - val_accuracy: 0.7807\n",
      "Epoch 98/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 0.9850 - accuracy: 0.7567 - val_loss: 0.8891 - val_accuracy: 0.7740\n",
      "Epoch 99/100\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 1.0051 - accuracy: 0.7508 - val_loss: 0.8217 - val_accuracy: 0.7904\n",
      "Epoch 100/100\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 1.0018 - accuracy: 0.7525 - val_loss: 0.8325 - val_accuracy: 0.7895\n"
     ]
    }
   ],
   "source": [
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "history = classifier.fit(image_ge.flow(x_train,y_train,batch_size = 25),epochs=100,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('./test0425.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[2.55108532e-03, 1.84481469e-05, 1.10352754e-04, 9.01590884e-01,\n",
       "        1.26449252e-02, 1.77490890e-07, 7.37183000e-05, 7.02636462e-05,\n",
       "        8.29149187e-02, 2.51464389e-05]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo2",
   "language": "python",
   "name": "geo2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}